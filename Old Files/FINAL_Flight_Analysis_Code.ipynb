{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                            DATA EXPLORATION & CLEAN-UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring Airport Code of Departure & Destination Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#-----------------------------####--------------------------------------------\n",
    "\n",
    "#Getting CSV file of the most populated cities in the world\n",
    "csv_path = \"Resources/Airport Codes/most_populated_cities_csv.csv\"\n",
    "most_populated_cities_df = pd.read_csv(csv_path,encoding=\"utf-8\")\n",
    "most_populated_cities_df.head()\n",
    "\n",
    "#Getting CSV file of the most visited cities in the world\n",
    "csv_path2 = \"Resources/Airport Codes/100_Most_visited_cities.csv\"\n",
    "most_visited_cities_df = pd.read_csv(csv_path2,encoding=\"utf-8\")\n",
    "most_visited_cities_df.head()\n",
    "\n",
    "\n",
    "###-----------------------------#####--------------------------------\n",
    "\n",
    "## Data Acquisitio Outbound Cities#####\n",
    "\n",
    "#List of outbound cities\n",
    "outbound_cities = ['Houston','Chicago','New York','Atlanta','Los Angeles','Seattle']\n",
    "\n",
    "#Empty list to append data acquired\n",
    "outbound_name = []\n",
    "destination_country = []\n",
    "airportID =[]\n",
    "airportName = []\n",
    "\n",
    "#City counter kick off. \n",
    "city_counter = 1\n",
    "\n",
    "#Base url\n",
    "url = \"https://skyscanner-skyscanner-flight-search-v1.p.rapidapi.com/apiservices/autosuggest/v1.0/USA/USD/en-US/?query=\"\n",
    "\n",
    "#Print statement to inform when data acquisition start\n",
    "print(f\"Beginning Data Acquisition of Departure City (Airport Code)\")\n",
    "print(f\"------------&&&&-------------------\")\n",
    "\n",
    "for i in tqdm(outbound_cities):\n",
    "    try:\n",
    "        #Getting the API with the first outbound city in the list (Houston) and loop thru the list\n",
    "        response = requests.get(url+i,\n",
    "          headers={\n",
    "            \"X-RapidAPI-Host\": \"skyscanner-skyscanner-flight-search-v1.p.rapidapi.com\",\n",
    "            \"X-RapidAPI-Key\": \"09ec0160admsh2d5563a7feaa3efp1e2db5jsn5787845ed7fc\"\n",
    "          }\n",
    "    ).json()\n",
    "        #Export the name and the ID\n",
    "        outbound_name.append(response[\"Places\"][0][\"PlaceName\"])\n",
    "        airportID.append(response[\"Places\"][1][\"PlaceId\"])\n",
    "        airportName.append(response[\"Places\"][1][\"PlaceName\"])\n",
    "        current_city = response[\"Places\"][0][\"PlaceName\"]\n",
    "        \n",
    "        print(f\"Data Acquisition {city_counter} | Outbound City: {current_city}\")  \n",
    "        city_counter = city_counter + 1\n",
    "    except:\n",
    "        print(\"Not a major outbound city\")\n",
    "    continue\n",
    "    \n",
    "# Print statement to inform when all records have been acquired.\n",
    "print(f\"------------&&&&---------------\")\n",
    "print(f\"Data Acquisition Complete\")\n",
    "print(f\"------------&&&&---------------\")\n",
    "\n",
    "#---------------------############------------------------------#\n",
    "#Creating a data frame of the data acquired\n",
    "outbound_data = {\"City Name\": outbound_name, \"Airport Name\": airportName, \"Airport Code\": airportID}\n",
    "outbound_data_df = pd.DataFrame(outbound_data)\n",
    "#Exporting data frame to csv file\n",
    "export_csv = outbound_data_df.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\City_departure_dataFinal.csv',index = False)\n",
    "#Transform the Airport code data into a list in order to used for the other API\n",
    "outbound_airport_code_list = outbound_data_df['Airport Code'].tolist()\n",
    "\n",
    "#---------------------###########--------------------------------#\n",
    "\n",
    "#Reading the Most visited Cities file#\n",
    "\n",
    "#Converting City Name into a list to gather airport code\n",
    "#https://stackoverflow.com/questions/22341271/get-list-from-pandas-dataframe-column/22341390\n",
    "city_destination_most_visited_list = most_visited_cities_df[\"City Name\"].tolist()\n",
    "\n",
    "city_destination_most_visited_list\n",
    "\n",
    "#--------------------------------#########-------------------------------------------\n",
    "\n",
    "## Destination Most Visited Cities ######\n",
    "\n",
    "#Empty list to store data\n",
    "visited_destination_name = []\n",
    "visited_country = []\n",
    "visited_destination_airportID =[]\n",
    "visited_destination_airportName = []\n",
    "\n",
    "visited_dest_city_counter = 1\n",
    "\n",
    "#Base URL\n",
    "url = \"https://skyscanner-skyscanner-flight-search-v1.p.rapidapi.com/apiservices/autosuggest/v1.0/USA/USD/en-US/?query=\"\n",
    "#Print statement to inform when data acquisition start\n",
    "print(f\"Beginning Data Acquisition of Destination City and respective Airport Codes\")\n",
    "print(f\"------------&&&&-------------------\")\n",
    "\n",
    "for z in tqdm(city_destination_most_visited_list):\n",
    "    try:\n",
    "        response = requests.get(url+z,\n",
    "          headers={\n",
    "            \"X-RapidAPI-Host\": \"skyscanner-skyscanner-flight-search-v1.p.rapidapi.com\",\n",
    "            \"X-RapidAPI-Key\": \"09ec0160admsh2d5563a7feaa3efp1e2db5jsn5787845ed7fc\"\n",
    "          }\n",
    "    ).json()\n",
    "        visited_destination_name.append(response[\"Places\"][0][\"PlaceName\"])\n",
    "        visited_country.append(response[\"Places\"][0][\"CountryName\"])\n",
    "        visited_destination_airportID.append(response[\"Places\"][1][\"PlaceId\"])\n",
    "        visited_destination_airportName.append(response[\"Places\"][1][\"PlaceName\"])\n",
    "        visited_destination_city = response[\"Places\"][0][\"PlaceName\"]\n",
    "        \n",
    "        print(f\"Data Acquisition {visited_dest_city_counter} | Outbound City: {visited_destination_city}\")  \n",
    "        visited_dest_city_counter = visited_dest_city_counter + 1\n",
    "    except:\n",
    "        print(\"Not a good city to travel... try another city\")\n",
    "    continue\n",
    "    \n",
    "# Print statement to inform when all records have been acquired.\n",
    "print(f\"------------&&&&---------------\")\n",
    "print(f\"Data Acquisition Complete\")\n",
    "print(f\"------------&&&&---------------\")\n",
    "\n",
    "##-----------------------------####------------------------------------------------------------------------\n",
    "\n",
    "#Creating data frame of Airport Name and Airport Code of the data acquired\n",
    "most_visited_destination_data =  {\"Airport Name\": visited_destination_airportName, \"Airport Code\": visited_destination_airportID }\n",
    "most_visited_destination_data = pd.DataFrame(most_visited_destination_data)\n",
    "\n",
    "#Exporting file to CSV format\n",
    "export_csv = most_visited_destination_data.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\most_visited_destination_dataFINAL.csv',index = False)\n",
    "\n",
    "#most_visited_destination_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring travel routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading outbound cities data csv \n",
    "outbound_data = \"Resources/Airport Codes/City_departure_dataFinal.csv\"\n",
    "outbound_data_df = pd.read_csv(outbound_data,encoding=\"utf-8\")\n",
    "outbound_data_df.head()\n",
    "\n",
    "#Reading csv of most visited cities\n",
    "most_visited_destination = \"Resources/Airport Codes/most_visited_destination_dataFINAL.csv\"\n",
    "most_visited_cities_df = pd.read_csv(most_visited_destination,encoding=\"utf-8\")\n",
    "\n",
    "#Creating a list of the name for the outbound airport cities\n",
    "outbound_airport_code_tolist = outbound_data_df['Airport Code'].tolist()\n",
    "\n",
    "#Creating a list for name of the airport of the most visited cities\n",
    "most_visited_cities_airport_list = most_visited_cities_df['Airport Code'].tolist()\n",
    "\n",
    "#------------------------------------###--------------------------------------------------------\n",
    "\n",
    "# Routes for all most visitied cities and one city outbound and fixed dates\n",
    "\n",
    "#Empty list to store data\n",
    "carriers_info = []\n",
    "places_info = []\n",
    "quotes_info = []\n",
    "\n",
    "#Base API url for routes\n",
    "base_url = \"https://skyscanner-skyscanner-flight-search-v1.p.rapidapi.com/apiservices/browseroutes/v1.0/US/USD/en-US/\"\n",
    "\n",
    "headers={\"X-RapidAPI-Host\": \"skyscanner-skyscanner-flight-search-v1.p.rapidapi.com\",\n",
    "    \"X-RapidAPI-Key\": \"077cfd7813mshfe97bf766bd036dp106fd9jsneb6caf492da9\"}\n",
    "\n",
    "#Variables for the url\n",
    "originplace = outbound_airport_code_tolist\n",
    "destinationplace = most_visited_cities_airport_list\n",
    "outboundpartialdate = [\"2019-12-15\"]\n",
    "inboundpartialdate = [\"2020-01-05\"]\n",
    "\n",
    "#Start counter for the loop\n",
    "destination_counter = 1\n",
    "\n",
    "#Print statement to inform when data acquisition start\n",
    "print(f\"Beginning Data Acquisition from {outbound_airport_code_tolist[1]} airport to the most visited cities in the world !!!\")\n",
    "print(f\"------------&&&&-------------------\")\n",
    "\n",
    "for x in tqdm(destinationplace):\n",
    "    try:\n",
    "        response = requests.get(base_url+outbound_airport_code_tolist[1]+\"/\"+x+ \"/\"+outboundpartialdate[0]+\"?inboundpartialdate=\"+inboundpartialdate[0], headers=headers).json()\n",
    "        #Append values to the empty list\n",
    "        carriers_info.append(response['Carriers'])\n",
    "        places_info.append(response['Places'])\n",
    "        quotes_info.append(response['Quotes'])\n",
    "        \n",
    "        print(f\"Data Acquisition {destination_counter} | Outbound City: {outbound_airport_code_tolist[1]}\")  \n",
    "        \n",
    "        destination_counter = destination_counter + 1\n",
    "    except:\n",
    "        print(\"Route not found...!!\")\n",
    "    continue\n",
    "    \n",
    "# Print statement to inform when all records have been acquired.\n",
    "print(f\"------------&&&&---------------\")\n",
    "print(f\"Data Acquisition Complete\")\n",
    "print(f\"------------&&&&---------------\")      \n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "#Loop thru the carriers information data that contains independent dictionaries and append results to a empty list\n",
    "carriers_list = []\n",
    "for x in range(len(carriers_info)):\n",
    "    for y in range(len(carriers_info[x])):\n",
    "        #print(carriers_info[x][y])\n",
    "        carriers_list.append(carriers_info[x][y])\n",
    "        \n",
    "\n",
    "#Loop thru the places information data that contains dictionaries and append results to a empty list\n",
    "places_list = []\n",
    "for i in range(len(places_info)):\n",
    "    for j in range(len(places_info[i])):\n",
    "        #print(places_info[i][j])\n",
    "        places_list.append(places_info[i][j])\n",
    "        \n",
    "#Loop thru the quoute information data that contains nested dictionaries and append results to a empty list\n",
    "#Noted the nested dictionary of the outboundleg which is append to the outbound list\n",
    "quotes_list = []\n",
    "outbound_list = []\n",
    "for z in range(len(quotes_info)):\n",
    "    for w in range(len(quotes_info[z])):\n",
    "        quotes_list.append(quotes_info[z][w])\n",
    "        outbound_list.append(quotes_info[z][w]['OutboundLeg'])    \n",
    "        \n",
    "##################################################################################################################3\n",
    "\n",
    "#Creating the data frame of carrriers\n",
    "carriers_df = pd.DataFrame(carriers_list)\n",
    "carriers_df\n",
    "#Exporting dataframe into csv format\n",
    "export_csv = carriers_df.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\carriers_df.csv',index = False)\n",
    "len(carriers_df)\n",
    "\n",
    "#######################################################################################################################\n",
    "#Creating the data frame for places\n",
    "places_df = pd.DataFrame(places_list)\n",
    "places_df\n",
    "#Exporting dataframe into csv format\n",
    "export_csv = places_df.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\placescsv.csv',index = False)\n",
    "places_df\n",
    "\n",
    "####################################################################################################################\n",
    "#Create the data frame of the quotes list\n",
    "quotes_df = pd.DataFrame(quotes_list)\n",
    "quotes_df.head()\n",
    "\n",
    "#Create the data frame of the outbound list\n",
    "outbound_df = pd.DataFrame(outbound_list)\n",
    "outbound_df\n",
    "\n",
    "#Merged both data frames together on the index since data is symetric\n",
    "merged_quotes_outbound = pd.merge(quotes_df,outbound_df, left_index = True, right_index = True)\n",
    "merged_quotes_outbound\n",
    "\n",
    "#Export to CSV \n",
    "export_csv = merged_quotes_outbound.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\merged_quotes_outbound.csv',index = False)\n",
    "#merged_quotes_outbound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading & Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################ Reading CSV ##################################\n",
    "\n",
    "# #Reading carriers data csv \n",
    "# carriers_data = \"Resources/Seattle Data/SE_carriers_df.csv\"\n",
    "# carriers_data_df = pd.read_csv(carriers_data,encoding=\"utf-8\")\n",
    "\n",
    "# # Merge Airline Name, keep in mind that a dictionary has been created for the data frame of carriers to eliminate duplicates\n",
    "# #https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict\n",
    "# #This is the dictionary\n",
    "# airlines_dict = {row[0]: row[1] for k, row in carriers_data_df.iterrows()}\n",
    "# airlines_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ########################### Carriers Data ##################################################\n",
    "\n",
    "\n",
    "\n",
    "# #Renaming columns\n",
    "# #https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n",
    "# carriers_data_df = carriers_data_df.rename(columns={'CarrierId': 'Airline ID', 'Name':'Airline Name'})\n",
    "\n",
    "# convert_dict2 = {'Airline ID': object}\n",
    "# carriers_data_df = carriers_data_df.astype(convert_dict2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carriers_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ########################## Quotes Data #######################################################\n",
    "\n",
    "\n",
    "# #Reading Quoutes data csv\n",
    "# quotes_data = \"Resources/Seattle Data/SE_merged_quotes_outbound.csv\"\n",
    "# quotes_data_df = pd.read_csv(quotes_data,encoding=\"utf-8\")\n",
    "# quotes_data_df.head()\n",
    "\n",
    "# #Delete columns that we don't use\n",
    "# #https://www.shanelynn.ie/using-pandas-dataframe-creating-editing-viewing-data-in-python/\n",
    "# quotes_data_df = quotes_data_df.drop(['OutboundLeg','QuoteDateTime'], axis =1)\n",
    "\n",
    "# #Delete the brackets from carrier Ids\n",
    "# quotes_data_df['CarrierIds'] = quotes_data_df['CarrierIds'].str.replace(\"[\",\"\")\n",
    "# quotes_data_df['CarrierIds'] = quotes_data_df['CarrierIds'].str.replace(\"]\",\"\")\n",
    "\n",
    "# #Delete the time from the daparture date\n",
    "# quotes_data_df['DepartureDate'] = quotes_data_df['DepartureDate'].str.replace(\"T00:00:00\",\"\")\n",
    "\n",
    "# #Change order of columns \n",
    "# #https://erikrood.com/Python_References/change_order_dataframe_columns_final.html\n",
    "# quotes_data_df = quotes_data_df[['OriginId','DestinationId','MinPrice','CarrierIds','Direct','DepartureDate','QuoteId']]\n",
    "\n",
    "# #Renaming columns\n",
    "# #https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n",
    "# quotes_data_df = quotes_data_df.rename(columns={'OriginId': 'City ID Departure', 'DestinationId':'City ID','MinPrice':'Min Price', 'CarrierIds': 'Airline ID', 'Direct': 'Non-Stop Flight', 'DepartureDate':'Departure Date', 'QuoteId': 'Quote ID'})\n",
    "\n",
    "# #Change Airline ID to numeric\n",
    "# #https://www.geeksforgeeks.org/change-data-type-for-one-or-more-columns-in-pandas-dataframe/\n",
    "# # convert_dict = {'Airline ID': object}\n",
    "# # quotes_data_df = quotes_data_df.astype(convert_dict) \n",
    "# quotes_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################### Places Data ######################################################################\n",
    "\n",
    "# #Reading places data csv\n",
    "# places_data = \"Resources/Seattle Data/SEplacescsv.csv\"\n",
    "# places_data_df = pd.read_csv(places_data,encoding=\"utf-8\")\n",
    "# places_data_df.head()\n",
    "\n",
    "# #Drop/remove entire column CityId, Type, drop SkyscannerCode, change PlaceId to string\n",
    "# #Delete columns that we don't use\n",
    "# #https://www.shanelynn.ie/using-pandas-dataframe-creating-editing-viewing-data-in-python/\n",
    "# places_data_df = places_data_df.drop(['CityId','Type','SkyscannerCode'], axis =1)\n",
    "\n",
    "# #Change order of columns \n",
    "# #https://erikrood.com/Python_References/change_order_dataframe_columns_final.html\n",
    "# places_data_df = places_data_df[['PlaceId','CityName','Name','IataCode','CountryName']]\n",
    "\n",
    "# #Renaming columns\n",
    "# #https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n",
    "# places_data_df = places_data_df.rename(columns={'CityName': 'City Name', 'CountryName':'Country Name','IataCode':'Iata Code', 'Name': 'Airport Name', 'PlaceId': 'City ID'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################### Merging ###########################################################################\n",
    "\n",
    "# #Merge quoutes and places\n",
    "# merge_1 = pd.merge(places_data_df, quotes_data_df, how = 'outer', on = 'City ID' )\n",
    "# #merge_1.head(1000)\n",
    "\n",
    "# #Drop NA values\n",
    "# #http://www.datasciencemadesimple.com/drop-rows-with-nan-na-drop-missing-value-in-pandas-python-2/\n",
    "# merge_1 = merge_1.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Map the city name to the Airline ID by creating a new Airline Name column\n",
    "# merge_1['Airline Name'] = merge_1['Airline ID'].map(airlines_dict)\n",
    "# merge_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################################ Export to CSV ###############################################################\n",
    "\n",
    "# #Export and save to CSV\n",
    "# export_csv = merge_1.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\MergeCleanFINAL.csv',index = False)\n",
    "\n",
    "\n",
    "# #Export clean data frame to csv\n",
    "# export_csv = places_data_df.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\placesCLEAN.csv',index = False)\n",
    "\n",
    "# #Export clean data frame to csv\n",
    "# export_csv = quotes_data_df.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\quotesCLEAN.csv',index = False)\n",
    "\n",
    "\n",
    "# #Export clean data frame to csv\n",
    "# export_csv = carriers_data_df.to_csv(r'C:\\Users\\pablo\\Google Drive\\Certifications\\Rice Data Analytics\\HomeWorks_Projects\\COPY_Project_1\\Resources\\carriersCLEAN.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
